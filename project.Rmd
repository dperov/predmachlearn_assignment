---
title: "Practical Machine Learning Course Project"
author: "Dmitri Perov"
date: "January 28, 2016"
output: html_document
---
#Summary

The goal of this project is to create prediction model for "classe" variable in the training set.

The dataset first was preprocessed and only meanful feature remained.

Two models were tested - Decision Tree (RPART) and Random Forest.

Decision tree model showed low accuracy ( 0.5 ) and would not provide good results with testing dataset.

Accuracy of Random Forest model is much higher ( 0.99 ). 

This model used to predict the testing dataset and gave 100% correct prediction. 


#Data preprocessing

It is assumed that original dataset is already downloaded into current directory.

Current directory should contain files **pml-testing.csv** and **pml-training.csv**.

```{r, echo=FALSE}
load(".RData")
```

Loading required libraries
```{r, error=FALSE, message=FALSE}
library(ggplot2)
library(caret)
```

Loading original training dataset
```{r cache=TRUE}
data <- read.csv("pml-training.csv", dec = ".")
# remove row 5373, which contains outliner
data <- data[-5373,]
```

Original dataset countans `r nrow(data)` observation in `r ncol(data)` variables.

Check how many NAs contains each of the variables (columns)
```{r }
calc_na <- function(name, dataset) sum(is.na(dataset[,name]))
na_count <- data.frame(name=names(data), na=sapply(names(data), calc_na, dataset=data))
na_cols <- na_count[na_count$na > 0,]$name
na_col_count <- length(na_cols)
```

We have `r na_col_count` which contains NAs. 

Our decision is to get rid of such column.

Also, columns 1-7 contains timestaps, ids and they are not needed for model training.

```{r }
data_subset <- data[, !names(data) %in% na_cols]
data_subset <- data_subset[-c(1:7)]
```
 
 Also, we removing column which are loaded as character strings.
```{r }
col_type_names <- sapply(data_subset, typeof)
character_cols <- col_type_names == "character"
data_subset <- data_subset[, !character_cols]
```

Then we visually inspected all the remaining  variables in dataset.

The following code is generating plot for each variable (not evaluated).

```{r, eval= FALSE}
for (col_name in names(data_subset)) {
  print(qplot(data_subset[,col_name], 1:nrow(data_subset),      colour=data$classe)+xlab(col_name));
}
```

Example of such plots are shown below.

Variables "min_yaw_belt", "magnet_forearm_z", "gyros_belt_y"
are shown on the following plots. 

Note the appearance of first plot (looks like random data) in comparision with the second and third plot
```{r, eval= TRUE}
for (col_name in c("min_yaw_belt", "magnet_forearm_z", "gyros_belt_y")) {
  print(qplot(data_subset[,col_name], 1:nrow(data_subset),      colour=data$classe)+xlab(col_name));
}
```

Visual inspection of the variables revealed that the vaiables whose name looks like

* min*
* max*
* kurtosis*
* skewness*
* amplitude*

are not correlated with classe variable

We removed all them from the dataset

```{r}
misc_cols <- grep("^(min|max|kurtosis|skewness|amplitude)", names(data_subset))
data_subset <- data_subset[, -misc_cols]
misc_cols_removed <- length(misc_cols)
misc_cols_removed
```
 

Data set contains now `r ncol(data_subset)` columns and it seems to be clean enouph to proceed with model training.
 
#Model training

First, try to implement some simple model, decision tree, and check what would be the accuracy.

```{r eval = FALSE}
model_rpart <- train(classe ~ ., data = data_subset, method = "rpart")
```

```{r}
model_rpart
```

caret package evaluates the model internally using bootsrapped resampling method and
found the model accuracy to be 0.5

This is definetly not enouph for successful evaluation our testing set.

So, we need to find more efficient model.

The next model we're going to test is Random Forest

RF model creatation is VERY time consuming process. 
Expect hours for the execution of the following code.

```{r eval = FALSE}
model <- train(classe ~ ., data = data_subset3, method = "rf")
```

Random Forest model is  much more accurate.

```{r}
model
```

Model accuracy that was internally evaluated by caret package using bootstrapped resampling is 0.99 

#Model testing

Load testing dataset and applying Random Forest model on it

```{r}
testing <- read.csv("pml-testing.csv", dec = ".")
predict(model, testing)
```
 
These results are the keys for the Course  Quiz 4.

Applying these keys to the quiz reveals that the results are 100% accurate.

